{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import PredefinedSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipped loading some Tensorflow models, missing a dependency. No module named 'tensorflow'\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch_geometric'\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. cannot import name 'DMPNN' from 'deepchem.models.torch_models' (/home/simon/miniconda3/envs/lohi_benchmark/lib/python3.10/site-packages/deepchem/models/torch_models/__init__.py)\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../../../../code')\n",
    "\n",
    "from metrics import get_hi_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2089</th>\n",
       "      <td>O=C(CN1C(=O)CCC1=O)Nc1ccc(F)c(F)c1F</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>COc1ccc(-c2nnc(NC(=O)c3ccc4ccccc4c3)o2)cc1OC</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>O=C(Nc1ccc2ccccc2n1)c1ccc(N2CCOC2=O)cc1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Cc1c[nH]c(=O)n1-c1ccc(C(=O)Nc2ccc3ccccc3n2)cc1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>O=C(C1CCC(O)CC1)N1CCCN(c2ccc(F)cc2)CC1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2143</th>\n",
       "      <td>N#CCCn1nc(C(F)(F)F)cc1O</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2147</th>\n",
       "      <td>Cc1ccccc1N1C(=O)c2ccc(C(=O)NC(C)(C)C)cc2C1=O</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2160</th>\n",
       "      <td>CC(C)(C)C(=O)Nc1sc2c(c1C#N)CCC2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2165</th>\n",
       "      <td>C[C@@H](c1ccc(F)cc1)n1nnc2cnc3ccc(-c4ccc5ocnc5...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2169</th>\n",
       "      <td>CCc1noc(COc2c(C)ccnc2Cl)n1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1442 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 smiles  value\n",
       "2089                O=C(CN1C(=O)CCC1=O)Nc1ccc(F)c(F)c1F  False\n",
       "2099       COc1ccc(-c2nnc(NC(=O)c3ccc4ccccc4c3)o2)cc1OC   True\n",
       "61              O=C(Nc1ccc2ccccc2n1)c1ccc(N2CCOC2=O)cc1   True\n",
       "89       Cc1c[nH]c(=O)n1-c1ccc(C(=O)Nc2ccc3ccccc3n2)cc1   True\n",
       "97               O=C(C1CCC(O)CC1)N1CCCN(c2ccc(F)cc2)CC1  False\n",
       "...                                                 ...    ...\n",
       "2143                            N#CCCn1nc(C(F)(F)F)cc1O  False\n",
       "2147       Cc1ccccc1N1C(=O)c2ccc(C(=O)NC(C)(C)C)cc2C1=O  False\n",
       "2160                    CC(C)(C)C(=O)Nc1sc2c(c1C#N)CCC2   True\n",
       "2165  C[C@@H](c1ccc(F)cc1)n1nnc2cnc3ccc(-c4ccc5ocnc5...   True\n",
       "2169                         CCc1noc(COc2c(C)ccnc2Cl)n1  False\n",
       "\n",
       "[1442 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('../../../../data/hi/sol/train_1.csv', index_col=0)\n",
    "test = pd.read_csv('../../../../data/hi/sol/test_1.csv', index_col=0)\n",
    "\n",
    "train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gb_gridsearch(train_fps, test_fps):\n",
    "    split_index = [-1] * len(train_fps) + [0] * len(test_fps)\n",
    "    pds = PredefinedSplit(test_fold = split_index)\n",
    "\n",
    "    X = train_fps + test_fps\n",
    "    y = train['value'].to_list() + test['value'].to_list()\n",
    "\n",
    "    params = {\n",
    "    'n_estimators': [10, 50, 100, 150, 200, 250, 500],\n",
    "    'learning_rate': [0.01, 0.1, 0.3, 0.5, 0.7, 1.0],\n",
    "    'subsample': [0.4, 0.7, 0.9, 1.0],\n",
    "    'min_samples_split': [2, 3, 5, 7],\n",
    "    'min_samples_leaf': [1, 3, 5],\n",
    "    'max_depth': [2, 3, 4],\n",
    "    'max_features': [None, 'sqrt']\n",
    "    }\n",
    "    knn = GradientBoostingClassifier()\n",
    "\n",
    "    grid_search = RandomizedSearchCV(knn, params, cv=pds, n_iter=30, refit=False, scoring='average_precision', verbose=3)\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    best_params = grid_search.best_params_\n",
    "    print(best_params)\n",
    "    knn = GradientBoostingClassifier(**best_params)\n",
    "    knn.fit(train_fps, train['value'])\n",
    "\n",
    "    test_preds = knn.predict_proba(test_fps)[:, 1]\n",
    "    test_metrics = get_hi_metrics(test, test_preds)\n",
    "    return test_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 30 candidates, totalling 30 fits\n",
      "[CV 1/1] END learning_rate=0.1, max_depth=3, max_features=None, min_samples_leaf=5, min_samples_split=3, n_estimators=500, subsample=0.4;, score=0.419 total time=   7.2s\n",
      "[CV 1/1] END learning_rate=0.3, max_depth=3, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=50, subsample=0.4;, score=0.382 total time=   0.9s\n",
      "[CV 1/1] END learning_rate=0.7, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, n_estimators=50, subsample=0.7;, score=0.385 total time=   0.9s\n",
      "[CV 1/1] END learning_rate=0.1, max_depth=4, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, n_estimators=50, subsample=1.0;, score=0.459 total time=   0.9s\n",
      "[CV 1/1] END learning_rate=1.0, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=250, subsample=0.4;, score=0.247 total time=   1.1s\n",
      "[CV 1/1] END learning_rate=0.5, max_depth=2, max_features=None, min_samples_leaf=5, min_samples_split=5, n_estimators=250, subsample=0.7;, score=0.373 total time=   4.9s\n",
      "[CV 1/1] END learning_rate=0.3, max_depth=2, max_features=None, min_samples_leaf=3, min_samples_split=7, n_estimators=150, subsample=0.7;, score=0.376 total time=   3.2s\n",
      "[CV 1/1] END learning_rate=0.3, max_depth=3, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=250, subsample=1.0;, score=0.486 total time=   1.3s\n",
      "[CV 1/1] END learning_rate=0.01, max_depth=3, max_features=None, min_samples_leaf=3, min_samples_split=5, n_estimators=150, subsample=1.0;, score=0.446 total time=   5.7s\n",
      "[CV 1/1] END learning_rate=0.1, max_depth=4, max_features=None, min_samples_leaf=5, min_samples_split=7, n_estimators=150, subsample=1.0;, score=0.422 total time=   7.3s\n",
      "[CV 1/1] END learning_rate=0.3, max_depth=3, max_features=None, min_samples_leaf=3, min_samples_split=5, n_estimators=250, subsample=1.0;, score=0.409 total time=   8.8s\n",
      "[CV 1/1] END learning_rate=0.7, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=3, n_estimators=150, subsample=0.7;, score=0.350 total time=   1.0s\n",
      "[CV 1/1] END learning_rate=0.3, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=10, subsample=0.7;, score=0.351 total time=   0.8s\n",
      "[CV 1/1] END learning_rate=1.0, max_depth=4, max_features=None, min_samples_leaf=5, min_samples_split=3, n_estimators=50, subsample=0.4;, score=0.244 total time=   1.6s\n",
      "[CV 1/1] END learning_rate=0.1, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=200, subsample=1.0;, score=0.448 total time=   1.3s\n",
      "[CV 1/1] END learning_rate=1.0, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=10, subsample=0.4;, score=0.272 total time=   0.8s\n",
      "[CV 1/1] END learning_rate=0.5, max_depth=4, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=200, subsample=0.4;, score=0.235 total time=   1.2s\n",
      "[CV 1/1] END learning_rate=0.3, max_depth=3, max_features=sqrt, min_samples_leaf=1, min_samples_split=3, n_estimators=500, subsample=0.9;, score=0.446 total time=   1.7s\n",
      "[CV 1/1] END learning_rate=0.01, max_depth=3, max_features=sqrt, min_samples_leaf=3, min_samples_split=5, n_estimators=250, subsample=0.7;, score=0.438 total time=   1.2s\n",
      "[CV 1/1] END learning_rate=0.01, max_depth=2, max_features=sqrt, min_samples_leaf=1, min_samples_split=7, n_estimators=100, subsample=0.4;, score=0.437 total time=   0.9s\n",
      "[CV 1/1] END learning_rate=0.5, max_depth=3, max_features=None, min_samples_leaf=1, min_samples_split=2, n_estimators=500, subsample=0.9;, score=0.404 total time=  15.8s\n",
      "[CV 1/1] END learning_rate=0.7, max_depth=2, max_features=None, min_samples_leaf=5, min_samples_split=5, n_estimators=50, subsample=1.0;, score=0.337 total time=   1.9s\n",
      "[CV 1/1] END learning_rate=0.1, max_depth=2, max_features=None, min_samples_leaf=3, min_samples_split=7, n_estimators=500, subsample=0.9;, score=0.430 total time=  10.3s\n",
      "[CV 1/1] END learning_rate=0.7, max_depth=4, max_features=None, min_samples_leaf=3, min_samples_split=2, n_estimators=500, subsample=0.9;, score=0.403 total time=  11.8s\n",
      "[CV 1/1] END learning_rate=1.0, max_depth=4, max_features=None, min_samples_leaf=3, min_samples_split=3, n_estimators=10, subsample=0.4;, score=0.278 total time=   0.6s\n",
      "[CV 1/1] END learning_rate=0.1, max_depth=2, max_features=sqrt, min_samples_leaf=5, min_samples_split=2, n_estimators=10, subsample=0.7;, score=0.375 total time=   0.5s\n",
      "[CV 1/1] END learning_rate=0.5, max_depth=4, max_features=None, min_samples_leaf=1, min_samples_split=7, n_estimators=150, subsample=0.4;, score=0.243 total time=   2.0s\n",
      "[CV 1/1] END learning_rate=1.0, max_depth=3, max_features=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50, subsample=0.4;, score=0.254 total time=   0.9s\n",
      "[CV 1/1] END learning_rate=1.0, max_depth=4, max_features=None, min_samples_leaf=1, min_samples_split=3, n_estimators=10, subsample=0.4;, score=0.283 total time=   0.6s\n",
      "[CV 1/1] END learning_rate=0.5, max_depth=4, max_features=sqrt, min_samples_leaf=5, min_samples_split=5, n_estimators=200, subsample=0.7;, score=0.389 total time=   0.7s\n",
      "{'subsample': 1.0, 'n_estimators': 250, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 3, 'learning_rate': 0.3}\n",
      "{'roc_auc': 0.7102884637003396, 'bedroc': 0.5514423015524115, 'prc_auc': 0.391209019813132}\n"
     ]
    }
   ],
   "source": [
    "train_mols = [Chem.MolFromSmiles(x) for x in train['smiles']]\n",
    "train_morgan_fps = [AllChem.GetMorganFingerprintAsBitVect(x, 2, 1024) for x in train_mols]\n",
    "\n",
    "test_mols = [Chem.MolFromSmiles(x) for x in test['smiles']]\n",
    "test_morgan_fps = [AllChem.GetMorganFingerprintAsBitVect(x, 2, 1024) for x in test_mols]\n",
    "\n",
    "test_metrics = run_gb_gridsearch(train_morgan_fps, test_morgan_fps)\n",
    "print(test_metrics)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict(train, test):\n",
    "    train_mols = [Chem.MolFromSmiles(x) for x in train['smiles']]\n",
    "    train_morgan_fps = [AllChem.GetMorganFingerprintAsBitVect(x, 2, 1024) for x in train_mols]\n",
    "\n",
    "    test_mols = [Chem.MolFromSmiles(x) for x in test['smiles']]\n",
    "    test_morgan_fps = [AllChem.GetMorganFingerprintAsBitVect(x, 2, 1024) for x in test_mols]\n",
    "\n",
    "    gb = GradientBoostingClassifier(\n",
    "        n_estimators=250,\n",
    "        subsample=1.0,\n",
    "        min_samples_split=3,\n",
    "        min_samples_leaf=1,\n",
    "        max_features='sqrt',\n",
    "        max_depth=3,\n",
    "        learning_rate=0.3\n",
    "    )\n",
    "    gb.fit(train_morgan_fps, train['value'])\n",
    "\n",
    "    train_result = train.copy()\n",
    "    train_result['preds'] = train_result['value']\n",
    "\n",
    "    test_result = test.copy()\n",
    "    test_result['preds'] = gb.predict_proba(test_morgan_fps)[:, 1]\n",
    "\n",
    "    return train_result, test_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1, 2, 3]:\n",
    "    train = pd.read_csv(f'../../../../data/hi/sol/train_{i}.csv')\n",
    "    test = pd.read_csv(f'../../../../data/hi/sol/test_{i}.csv')\n",
    "\n",
    "    train_preds, test_preds = fit_predict(train, test)\n",
    "    train_preds.to_csv(f'../../../../predictions/hi/sol/gb_ecfp4/train_{i}.csv')\n",
    "    test_preds.to_csv(f'../../../../predictions/hi/sol/gb_ecfp4/test_{i}.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lohi_benchmark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
